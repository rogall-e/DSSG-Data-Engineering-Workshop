# DSFG - Data Engineering Workshop

Welcome to the Data Engineering Workshop organized by the Data Science for Good (DSFG) community. This workshop is designed to provide a hands-on introduction to the data engineering workflow and tools. The intended audience is data scientists and analysts who are interested in learning how to build simple data pipelines and data warehouses.

## What to expect
We are going to build a simple data pipeline that extracts data from a public API, stores it in a database, and makes it available for analysis. We will use a variety of tools to achieve this goal and we will discuss the advantages and disadvantages of each approach. The workshop will be a mix of presentations and hands-on exercises.

- Writing SQL queries
- Hearing some technical jargon like API, ETL, ELT, Data Warehouse, Data Lake, etc. We will explain what all of these terms mean.


## What not to expect
- Buildig a production-ready data pipeline.
- Interacting with all the bells and whistles of the tools we will use. We will focus on the core functionality.
- Lots to time to discuss the pros and cons of each tool. We will provide some first impressions and resources for further learning.


## Timetable
| Session                                              | Time          | Description                                                                                                                   | Tool             |
|------------------------------------------------------|---------------|-------------------------------------------------------------------------------------------------------------------------------|------------------|
| Giving Context and Getting to know each other         | 9:00 - 9:30   | Introduce the workshop objectives and participants share their backgrounds and expectations                                  |                  |
| Storing Data                                         | 9:30 - 10:15  | Persisting data in a secure and queryable location for analytics purposes                                                    | DuckDB           |
| Extracting and Loading                               | 10:30 - 11:15 | Transferring data from different systems to a centralized repository                                                          | Airbyte          |
| Transforming                                         | 11:30 - 12:30 | Shaping raw data from various sources into a unified view that can be interpreted by stakeholders                            | dbt              |
| Making data accessible                               | 12:45 - 13:15 | Providing interpretation and data access to the rest of the organization                                                     | Metabase         |
| Follow Up Questions and next steps                   | 13:15         | Participants can ask questions and receive guidance on recommended next steps and resources for further learning in data engineering |                  |

